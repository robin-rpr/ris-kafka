version: '3'
services:
    {%- for host in ris %}
    {{ host }}:
        {%- if production %}
        image: robinrpr/ris-kafka:{{ version | default('latest') }}
        {%- else %}
        build: .
        {%- endif %}
        deploy:
            replicas: {% raw %}${RRC_REPLICA_COUNT:-2}{% endraw %}
            restart_policy:
                condition: any
            placement:
                constraints:
                    - node.role == worker
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        restart: unless-stopped
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: {{ host }}
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            {%- if not production %}
            - .:/app
            {%- endif %}
            - {{ host }}_data:/var/lib/rocksdb
        entrypoint: >
            python app.py
    {% endfor %}
    
    zookeeper:
        image: confluentinc/cp-zookeeper:7.7.1
        restart: unless-stopped
        deploy:
            restart_policy:
                condition: any
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "nc -z localhost 2181 || exit 1"]
            interval: 30s
            timeout: 10s
            retries: 5
        volumes:
            - zookeeper_data:/var/lib/zookeeper
        environment:
            ZOOKEEPER_MAX_CLIENT_CNXNS: {% raw %}${ZOOKEEPER_MAX_CLIENT_CNXNS:-200}{% endraw %}
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000

    kafka:
        image: confluentinc/cp-kafka:7.7.1
        restart: unless-stopped
        deploy:
            placement:
                constraints:
                    - node.role == manager
            restart_policy:
                condition: any
        volumes:
            - kafka_data:/var/lib/kafka/data
        ports:
            - "9092:9092"
        environment:
            KAFKA_NODE_ID: 1
            CLUSTER_ID: "QTnB2tAgTWa1ec5wYon2jg"
            KAFKA_PROCESS_ROLES: "broker,controller"
            KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:SASL_PLAINTEXT,INTERNAL:SASL_PLAINTEXT,EXTERNAL:PLAINTEXT"
            KAFKA_LISTENERS: "CONTROLLER://0.0.0.0:9093,INTERNAL://0.0.0.0:29092,EXTERNAL://0.0.0.0:9092"
            KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka:29092,EXTERNAL://stream.ris-kafka.com:9092"
            KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
            KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
            KAFKA_SASL_ENABLED_MECHANISMS: "PLAIN"
            KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: "PLAIN"
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_AUTHORIZER_CLASS_NAME: org.apache.kafka.metadata.authorizer.StandardAuthorizer
            KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "false"
            KAFKA_SUPER_USERS: "User:admin"
            KAFKA_NUM_PARTITIONS: 1
            KAFKA_LOG_RETENTION_HOURS: 48
            KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 600000
            KAFKA_LOG_ROLL_MS: 3600000
            KAFKA_LOG_SEGMENT_BYTES: 1073741824 # 1GB
            KAFKA_MESSAGE_MAX_BYTES: 100000000
            KAFKA_LOG_CLEANER_THREADS: 2
            KAFKA_COMPRESSION_TYPE: lz4
            KAFKA_NUM_NETWORK_THREADS: {% raw %}${KAFKA_NUM_NETWORK_THREADS:-24}{% endraw %}
            KAFKA_NUM_IO_THREADS: {% raw %}${KAFKA_NUM_IO_THREADS:-24}{% endraw %}
            KAFKA_LISTENER_NAME_INTERNAL_SASL_ENABLED_MECHANISMS: PLAIN
            KAFKA_LISTENER_NAME_INTERNAL_PLAIN_SASL_JAAS_CONFIG: |
                org.apache.kafka.common.security.plain.PlainLoginModule required \
                username="admin" \
                password="admin-secret" \
                user_admin="admin-secret" \
                user_mds="mds-secret";

            KAFKA_LISTENER_NAME_CONTROLLER_SASL_ENABLED_MECHANISMS: PLAIN
            KAFKA_LISTENER_NAME_CONTROLLER_PLAIN_SASL_JAAS_CONFIG: |
                org.apache.kafka.common.security.plain.PlainLoginModule required \
                username="admin" \
                password="admin-secret" \
                user_admin="admin-secret" \
                user_mds="mds-secret";

            KAFKA_SASL_JAAS_CONFIG: |
                org.apache.kafka.common.security.plain.PlainLoginModule required \
                username="admin" \
                password="admin-secret";

            KAFKA_SASL_MECHANISM_CONTROLLER_PROTOCOL: "PLAIN"

    acl:
        image: confluentinc/cp-kafka:latest
        depends_on:
            - kafka
        restart: unless-stopped
        deploy:
            placement:
                constraints:
                    - node.role == manager
            restart_policy:
                condition: on-failure
        environment:
            KAFKA_OPTS: "-Djava.security.auth.login.config=/etc/kafka/jaas.conf"
            KAFKA_SECURITY_PROTOCOL: SASL_PLAINTEXT
        command:
            - /bin/bash
            - -c
            - |
                echo 'KafkaClient {
                    org.apache.kafka.common.security.plain.PlainLoginModule required
                    username="admin"
                    password="admin-secret";
                };' > /etc/kafka/jaas.conf && \
                sleep 10 && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --command-config <(echo -e "security.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN") \
                            --add --allow-principal User:admin \
                            --operation All \
                            --topic '*' \
                            --group '*' \
                            --allow-host '*' && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --command-config <(echo -e "security.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN") \
                            --add --allow-principal User:ANONYMOUS \
                            --operation Read \
                            --topic '*' \
                            --group '*' \
                            --allow-host '*' && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --command-config <(echo -e "security.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN") \
                            --add --deny-principal User:ANONYMOUS \
                            --operation Write \
                            --topic '*' \
                            --allow-host '*' && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --command-config <(echo -e "security.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN") \
                            --add --deny-principal User:ANONYMOUS \
                            --operation Create \
                            --topic '*' \
                            --allow-host '*' && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --command-config <(echo -e "security.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN") \
                            --add --deny-principal User:ANONYMOUS \
                            --operation Delete \
                            --topic '*' \
                            --allow-host '*' && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --command-config <(echo -e "security.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN") \
                            --add --deny-principal User:ANONYMOUS \
                            --operation Alter \
                            --topic '*' \
                            --allow-host '*' && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --command-config <(echo -e "security.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN") \
                            --list

    kafbat:
        image: ghcr.io/kafbat/kafka-ui:latest
        restart: unless-stopped
        {%- if not production %}
        ports:
            - "8080:8080"
        {%- endif %}
        deploy:
            restart_policy:
                condition: any
        depends_on:
            - kafka
        environment:
            KAFKA_CLUSTERS_0_NAME: ris-kafka
            KAFKA_CLUSTERS_0_BOOTSTRAP_SERVERS: kafka:29092
            KAFKA_CLUSTERS_0_READONLY: "true"
            KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: SASL_PLAINTEXT
            KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM: PLAIN
            KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG: |
                org.apache.kafka.common.security.plain.PlainLoginModule required
                username="admin"
                password="admin-secret";

    {%- if production %}
    # Cloudflared Tunnel
    cloudflared:
        image: cloudflare/cloudflared:latest
        restart: unless-stopped
        deploy:
        placement:
            constraints:
                - node.role == manager
        healthcheck:
            test: ["CMD", "cloudflared", "--version"]
            interval: 30s
            timeout: 10s
            retries: 3
            start_period: 10s
        depends_on:
            - web
        entrypoint: |
            cloudflared tunnel run --token ${CLOUDFLARE_TUNNEL_TOKEN}
    {%- endif %}

# Define volumes
volumes:
    zookeeper_data:
    kafka_data:
    {%- for host in ris %}
    {{ host }}_data:
    {%- endfor %}