version: '3'
services:
    {%- for host in ris %}
    {{ host }}:
        {%- if production %}
        image: robinrpr/ris-kafka:{{ version | default('latest') }}
        {%- else %}
        build: .
        {%- endif %}
        deploy:
            replicas: 2
            restart_policy:
                condition: any
            placement:
                constraints:
                    - node.labels.ris-kafka-rrc == 1
        restart: unless-stopped
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_BACKUP_SIZE: 350000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: {{ host }}
        depends_on:
            - kafbat
            - kafka
            - zookeeper
        working_dir: /app
        volumes:
            {%- if not production %}
            - .:/app
            {%- endif %}
            - {{ host }}_data:/var/lib/rocksdb
        entrypoint: >
            python app.py
    {% endfor %}
    
    zookeeper:
        image: confluentinc/cp-zookeeper:7.7.1
        restart: unless-stopped
        deploy:
            restart_policy:
                condition: any
            placement:
                constraints:
                    - node.labels.ris-kafka-zookeeper == 1
        healthcheck:
            test: ["CMD-SHELL", "nc -z localhost 2181 || exit -1"]
            interval: 30s
            timeout: 10s
            retries: 5
        volumes:
            - zookeeper_data:/var/lib/zookeeper
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000

    kafka:
        image: confluentinc/cp-kafka:7.7.1
        restart: unless-stopped
        deploy:
            placement:
                constraints:
                    - node.labels.ris-kafka-kafka == 1
            restart_policy:
                condition: any
        depends_on:
            - zookeeper
        volumes:
            - kafka_data:/var/lib/kafka/data
        ports:
            - "9092:9092"
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://stream.ris-kafka.com:9092
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_NUM_PARTITIONS: 1
            KAFKA_LOG_RETENTION_HOURS: 48
            KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 600000
            KAFKA_LOG_ROLL_MS: 3600000
            KAFKA_LOG_SEGMENT_BYTES: 1073741824 # 1GB
            KAFKA_MESSAGE_MAX_BYTES: 100000000
            KAFKA_LOG_CLEANER_THREADS: 2
            KAFKA_COMPRESSION_TYPE: lz4
            KAFKA_NUM_NETWORK_THREADS: 24
            KAFKA_NUM_IO_THREADS: 24

    acl:
        image: confluentinc/cp-kafka:latest
        depends_on:
            - kafka
        restart: unless-stopped
        deploy:
            restart_policy:
                condition: on-failure
        command:
            - /bin/sh
            - -c
            - |
                sleep 300 && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --add --allow-principal User:ANONYMOUS \
                            --operation Read \
                            --topic '*' \
                            --group '*' \
                            --allow-host '*' &&
                kafka-acls --bootstrap-server kafka:29092 \
                            --add --allow-principal User:ANONYMOUS \
                            --operation Write \
                            --topic '*' \
                            --allow-host '*'

    kafbat:
        image: ghcr.io/kafbat/kafka-ui:latest
        restart: unless-stopped
        deploy:
            restart_policy:
                condition: any
            labels:
                - "traefik.enable=true"
                - "traefik.http.routers.riskafka.rule=Host(`ris-kafka.com`)"
                - "traefik.http.routers.riskafka.entrypoints=websecure"
                - "traefik.http.routers.riskafka.tls.certresolver=riskafka"
                - "traefik.http.services.riskafka.loadbalancer.server.port=8080"
        depends_on:
            - kafka
        environment:
            KAFKA_CLUSTERS_0_NAME: ris-kafka
            KAFKA_CLUSTERS_0_BOOTSTRAP_SERVERS: kafka:29092
            KAFKA_CLUSTERS_0_READONLY: "true"

    traefik:
        image: traefik:v2.4
        ports:
            - "80:80"
            - "443:443"
        deploy:
            restart_policy:
                condition: any
            placement:
                constraints:
                    - node.role == manager
        entrypoint:
            - sh
            - -c
        command: >
            "touch /data/acme.json && chmod 600 /data/acme.json && traefik \
            --entrypoints.web.address=:80 \
            --entrypoints.websecure.address=:443 \
            --providers.docker.swarmMode=true \
            --providers.docker.exposedbydefault=false \
            --certificatesresolvers.riskafka.acme.httpchallenge.entrypoint=web \
            --certificatesresolvers.riskafka.acme.email=hostmaster@ris-kafka.com \
            --certificatesresolvers.riskafka.acme.storage=/data/acme.json"
        volumes:
            - /var/run/docker.sock:/var/run/docker.sock:ro
            - traefik_data:/data

# Define volumes
volumes:
    zookeeper_data:
    traefik_data:
    kafka_data:
    {%- for host in ris %}
    {{ host }}_data:
    {%- endfor %}