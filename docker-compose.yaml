services:
    app:
        build: .
        container_name: app
        restart: unless-stopped
        environment:
            KAFKA_FQDN: kafka:29092
            REDIS_HOST: redis
            REDIS_PORT: 6379
            REDIS_DB: 0
            RIS_HOST: rrc13
        depends_on:
            redis:
                condition: service_healthy
            kafka:
                condition: service_healthy
        working_dir: /app
        volumes:
            - .:/app
        entrypoint: >
            python app.py

    redis:
        container_name: redis
        image: redis:latest
        restart: unless-stopped
        healthcheck:
            test: [ "CMD", "redis-cli", "--raw", "incr", "ping" ]
            interval: 30s
            timeout: 60s
            retries: 10
        volumes:
            - redis_data:/data
        ports:
            - "6379:6379"
        environment:
            - ALLOW_EMPTY_PASSWORD=yes

    zookeeper:
        container_name: zookeeper
        image: confluentinc/cp-zookeeper:7.7.1
        restart: unless-stopped
        volumes:
            - zookeeper_data:/var/lib/zookeeper
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000

    kafka:
        container_name: kafka
        image: confluentinc/cp-kafka:7.7.1
        restart: unless-stopped
        healthcheck:
            test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "kafka:29092"]
            interval: 30s
            timeout: 60s # Command may take some time.
            retries: 10
        # Change the mount point to where you want to store Kafka data.
        #   Normally 80GB or more
        volumes:
            - kafka_data:/var/lib/kafka/data
        ports:
            - "9092:9092"
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
            # Change/add listeners based on your FQDN that the host and other containers can access.  You can use
            #    an IP address as well. By default, only within the compose/containers can Kafka be accesssed
            #    using port 29092. Outside access can be enabled, but you should use an FQDN listener.
            #KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://<FQDN>:9092
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_NUM_PARTITIONS: 8
            KAFKA_LOG_RETENTION_MINUTES: 90
            KAFKA_LOG_ROLL_MS: 3600000
            KAFKA_LOG_SEGMENT_BYTES: 1073741824
            KAFKA_MESSAGE_MAX_BYTES: 100000000
            KAFKA_LOG_CLEANER_THREADS: 2

# Define volumes
volumes:
    zookeeper_data:
    kafka_data:
    redis_data: