version: '3'
services:
    rrc00:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc00
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc00_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((1 * 120)) && python app.py"
    
    rrc01:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc01
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc01_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((2 * 120)) && python app.py"
    
    rrc03:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc03
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc03_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((3 * 120)) && python app.py"
    
    rrc04:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc04
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc04_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((4 * 120)) && python app.py"
    
    rrc05:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc05
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc05_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((5 * 120)) && python app.py"
    
    rrc06:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc06
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc06_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((6 * 120)) && python app.py"
    
    rrc07:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc07
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc07_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((7 * 120)) && python app.py"
    
    rrc10:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc10
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc10_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((8 * 120)) && python app.py"
    
    rrc11:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc11
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc11_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((9 * 120)) && python app.py"
    
    rrc12:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc12
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc12_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((10 * 120)) && python app.py"
    
    rrc13:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc13
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc13_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((11 * 120)) && python app.py"
    
    rrc14:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc14
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc14_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((12 * 120)) && python app.py"
    
    rrc15:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc15
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc15_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((13 * 120)) && python app.py"
    
    rrc16:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc16
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc16_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((14 * 120)) && python app.py"
    
    rrc18:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc18
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc18_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((15 * 120)) && python app.py"
    
    rrc19:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc19
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc19_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((16 * 120)) && python app.py"
    
    rrc20:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc20
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc20_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((17 * 120)) && python app.py"
    
    rrc21:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc21
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc21_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((18 * 120)) && python app.py"
    
    rrc22:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc22
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc22_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((19 * 120)) && python app.py"
    
    rrc23:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc23
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc23_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((20 * 120)) && python app.py"
    
    rrc24:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc24
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc24_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((21 * 120)) && python app.py"
    
    rrc25:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc25
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc25_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((22 * 120)) && python app.py"
    
    rrc26:
        image: robinrpr/ris-kafka:1.3.6
        restart: "no"
        deploy:
            replicas: ${RRC_REPLICA_COUNT:-2}
            restart_policy:
                condition: none
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "ldb --db=/var/lib/rocksdb get hardlock --value_hex | grep -q '^0x01$$' && exit 1 || exit 0"]
            interval: 30s
            timeout: 10s
            retries: 5
        stop_signal: SIGTERM  # Wind down collector safely before stopping
        stop_grace_period: 20s # Wait for 20 seconds before forcefully stopping
        environment:
            RRC_ZOOKEEPER_CONNECT: zookeeper:2181
            RRC_KAFKA_CONNECT: kafka:29092
            RRC_KAFKA_USERNAME: admin
            RRC_KAFKA_PASSWORD: admin-secret
            RRC_BACKUP_SIZE: 200000
            RRC_QUEUE_SIZE: 100000
            RRC_BATCH_SIZE: 10000
            RRC_LOG_LEVEL: INFO
            RRC_HOST: rrc26
        depends_on:
            - kafbat
            - kafka
            - zookeeper
            - acl
        working_dir: /app
        volumes:
            - rrc26_data:/var/lib/rocksdb
        entrypoint: >
            bash -c "sleep $$((23 * 120)) && python app.py"
    
    
    zookeeper:
        image: confluentinc/cp-zookeeper:7.7.1
        restart: unless-stopped
        deploy:
            restart_policy:
                condition: any
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD-SHELL", "nc -z localhost 2181 || exit 1"]
            interval: 30s
            timeout: 10s
            retries: 5
        volumes:
            - zookeeper_data:/var/lib/zookeeper
        environment:
            ZOOKEEPER_MAX_CLIENT_CNXNS: ${ZOOKEEPER_MAX_CLIENT_CNXNS:-200}
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000

    kafka:
        image: confluentinc/cp-kafka:7.7.1
        restart: unless-stopped
        deploy:
            placement:
                constraints:
                    - node.role == manager
            restart_policy:
                condition: any
        volumes:
            - kafka_data:/var/lib/kafka/data
        ports:
            - "9092:9092"
        environment:
            KAFKA_NODE_ID: 1
            CLUSTER_ID: "QTnB2tAgTWa1ec5wYon2jg"
            KAFKA_PROCESS_ROLES: "broker,controller"
            KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:SASL_PLAINTEXT,INTERNAL:SASL_PLAINTEXT,EXTERNAL:PLAINTEXT"
            KAFKA_LISTENERS: "CONTROLLER://0.0.0.0:9093,INTERNAL://0.0.0.0:29092,EXTERNAL://0.0.0.0:9092"
            KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka:29092,EXTERNAL://stream.ris-kafka.com:9092"
            KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
            KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
            KAFKA_SASL_ENABLED_MECHANISMS: "PLAIN"
            KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: "PLAIN"
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
            KAFKA_AUTHORIZER_CLASS_NAME: org.apache.kafka.metadata.authorizer.StandardAuthorizer
            KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "false"
            KAFKA_SUPER_USERS: "User:admin"
            KAFKA_NUM_PARTITIONS: 1
            KAFKA_LOG_RETENTION_HOURS: 48
            KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 600000
            KAFKA_LOG_ROLL_MS: 3600000
            KAFKA_LOG_SEGMENT_BYTES: 1073741824 # 1GB
            KAFKA_MESSAGE_MAX_BYTES: 100000000
            KAFKA_LOG_CLEANER_THREADS: 2
            KAFKA_COMPRESSION_TYPE: lz4
            KAFKA_NUM_NETWORK_THREADS: ${KAFKA_NUM_NETWORK_THREADS:-24}
            KAFKA_NUM_IO_THREADS: ${KAFKA_NUM_IO_THREADS:-24}
            KAFKA_LISTENER_NAME_INTERNAL_SASL_ENABLED_MECHANISMS: PLAIN
            KAFKA_LISTENER_NAME_INTERNAL_PLAIN_SASL_JAAS_CONFIG: |
                org.apache.kafka.common.security.plain.PlainLoginModule required \
                username="admin" \
                password="admin-secret" \
                user_admin="admin-secret" \
                user_mds="mds-secret";

            KAFKA_LISTENER_NAME_CONTROLLER_SASL_ENABLED_MECHANISMS: PLAIN
            KAFKA_LISTENER_NAME_CONTROLLER_PLAIN_SASL_JAAS_CONFIG: |
                org.apache.kafka.common.security.plain.PlainLoginModule required \
                username="admin" \
                password="admin-secret" \
                user_admin="admin-secret" \
                user_mds="mds-secret";

            KAFKA_SASL_JAAS_CONFIG: |
                org.apache.kafka.common.security.plain.PlainLoginModule required \
                username="admin" \
                password="admin-secret";

            KAFKA_SASL_MECHANISM_CONTROLLER_PROTOCOL: "PLAIN"

    acl:
        image: confluentinc/cp-kafka:latest
        depends_on:
            - kafka
        restart: unless-stopped
        deploy:
            restart_policy:
                condition: on-failure
            placement:
                constraints:
                    - node.role == manager
        environment:
            KAFKA_OPTS: "-Djava.security.auth.login.config=/etc/kafka/jaas.conf"
            KAFKA_SECURITY_PROTOCOL: SASL_PLAINTEXT
        command:
            - /bin/bash
            - -c
            - |
                echo 'KafkaClient {
                    org.apache.kafka.common.security.plain.PlainLoginModule required
                    username="admin"
                    password="admin-secret";
                };' > /etc/kafka/jaas.conf && \
                sleep 10 && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --command-config <(echo -e "security.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN") \
                            --add --allow-principal User:admin \
                            --operation All \
                            --topic '*' \
                            --group '*' \
                            --allow-host '*' && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --command-config <(echo -e "security.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN") \
                            --add --allow-principal User:ANONYMOUS \
                            --operation Read \
                            --topic '*' \
                            --group '*' \
                            --allow-host '*' && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --command-config <(echo -e "security.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN") \
                            --add --deny-principal User:ANONYMOUS \
                            --operation Write \
                            --topic '*' \
                            --allow-host '*' && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --command-config <(echo -e "security.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN") \
                            --add --deny-principal User:ANONYMOUS \
                            --operation Create \
                            --topic '*' \
                            --allow-host '*' && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --command-config <(echo -e "security.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN") \
                            --add --deny-principal User:ANONYMOUS \
                            --operation Delete \
                            --topic '*' \
                            --allow-host '*' && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --command-config <(echo -e "security.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN") \
                            --add --deny-principal User:ANONYMOUS \
                            --operation Alter \
                            --topic '*' \
                            --allow-host '*' && \
                kafka-acls --bootstrap-server kafka:29092 \
                            --command-config <(echo -e "security.protocol=SASL_PLAINTEXT\nsasl.mechanism=PLAIN") \
                            --list

    kafbat:
        image: ghcr.io/kafbat/kafka-ui:latest
        restart: unless-stopped
        deploy:
            restart_policy:
                condition: any
            placement:
                constraints:
                    - node.role == manager
        depends_on:
            - kafka
        environment:
            KAFKA_CLUSTERS_0_NAME: ris-kafka
            KAFKA_CLUSTERS_0_BOOTSTRAP_SERVERS: kafka:29092
            KAFKA_CLUSTERS_0_READONLY: "true"
            KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: SASL_PLAINTEXT
            KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM: PLAIN
            KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG: |
                org.apache.kafka.common.security.plain.PlainLoginModule required
                username="admin"
                password="admin-secret";
    # Cloudflared Tunnel
    cloudflared:
        image: cloudflare/cloudflared:latest
        restart: unless-stopped
        deploy:
            placement:
                constraints:
                    - node.role == manager
        healthcheck:
            test: ["CMD", "cloudflared", "--version"]
            interval: 30s
            timeout: 10s
            retries: 3
            start_period: 10s
        depends_on:
            - web
        entrypoint: |
            cloudflared tunnel run --token ${CLOUDFLARE_TUNNEL_TOKEN}

# Define volumes
volumes:
    zookeeper_data:
    kafka_data:
    rrc00_data:
    rrc01_data:
    rrc03_data:
    rrc04_data:
    rrc05_data:
    rrc06_data:
    rrc07_data:
    rrc10_data:
    rrc11_data:
    rrc12_data:
    rrc13_data:
    rrc14_data:
    rrc15_data:
    rrc16_data:
    rrc18_data:
    rrc19_data:
    rrc20_data:
    rrc21_data:
    rrc22_data:
    rrc23_data:
    rrc24_data:
    rrc25_data:
    rrc26_data: